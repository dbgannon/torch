{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import numpy as np\n",
    "# ignore potential warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    x = torch.randn(4, 4)\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "g1 = nx.nx.erdos_renyi_graph(N, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAMP = 0.85\n",
    "K = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using the neteworkx librariy and the excellent dgl library from https://docs.dgl.ai/ NYU Shanghai \n",
    "by Prof. Zheng Zhang and Quan Gan.  The algorithm below is from their work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a utility that builds a torch-based graph from the nx graph\n",
    "def makeGraph(g1):\n",
    "    g = dgl.DGLGraph(g1)\n",
    "    for i in range(0, N-1):\n",
    "        g.add_edge(i, i+1)\n",
    "    g.add_edge(N-1, 0)\n",
    "    #print(g)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pagerank(g, device):\n",
    "    g.ndata['pv'] = torch.ones(N).to(device) / N\n",
    "    degrees = g.out_degrees(g.nodes()).type(torch.float32).to(device)\n",
    "\n",
    "    for k in range(K):\n",
    "        g.ndata['pv'] = g.ndata['pv'] / degrees\n",
    "        g.update_all(message_func=fn.copy_src(src='pv', out='m'),\n",
    "                     reduce_func=fn.sum(msg='m', out='pv'))\n",
    "        g.ndata['pv'] = (1 - DAMP) / N + DAMP * g.ndata['pv']\n",
    "    return g.ndata['pv']/g.ndata['pv'].norm()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic page rank algorithm is\n",
    "$$\n",
    "Pr(i) ~=~ \\frac{(1-d)}{N} ~+~ d \\sum_{j\\in link(i)}{\\frac{ Pr(j)}{out(j)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The flowing two versions use the iteration to solve for the Pr vector\n",
    "$$\n",
    "Pr_{i+1} ~=~  \\frac{(1-d)}{N} ~+~ d G \\cdot Out \\cdot Pr_{i}\n",
    "$$\n",
    "pagerank1 uses the sparse version of the linear algebra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pagerank1(g, K, device):\n",
    "    pva = torch.ones([N,1])/N\n",
    "    pv = pva.to(device)\n",
    "    #print(pv)\n",
    "    degreesa = 1.0/g.out_degrees(g.nodes()).type(torch.float32)\n",
    "    degrees = degreesa.reshape([N,1]).to(device)\n",
    "    edges = g.adjacency_matrix().to(device)\n",
    "    Idmpa = torch.ones([N,1])*(1-DAMP)/N\n",
    "    Idmp = Idmpa.to(device)\n",
    "    #gm = edges.to_dense()\n",
    "    gm = edges\n",
    "    for k in range(K):\n",
    "        pv = pv*degrees\n",
    "        q = torch.mm(gm, pv)\n",
    "        pv  = Idmp + DAMP * q\n",
    "    return pv/pv.norm()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second version uses the dense representation of the adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pagerank2(g, K, device):\n",
    "    pv = torch.ones([N]).to(device)/N\n",
    "    degrees = 1.0/g.out_degrees(g.nodes()).type(torch.float32)\n",
    "    degrees = degrees.to(device)\n",
    "    edges = g.adjacency_matrix().to(device)\n",
    "    Idmp = torch.ones([N])*(1.0-DAMP)/N\n",
    "    gm = edges.to_dense().to(device)\n",
    "    for k in range(K):\n",
    "        pv = pv*degrees\n",
    "        q = torch.mv(gm, pv)\n",
    "        pv  = Idmp + DAMP * q\n",
    "    return pv/pv.norm()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  third version moves the vector-vector multiply from the innerloop to a matrix matrix multiply outside the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pagerank3(g, K, device):\n",
    "    pv = torch.ones([N]).to(device)/N\n",
    "    degrees = 1.0/g.out_degrees(g.nodes()).type(torch.float32)\n",
    "    degrees = degrees.to(device)\n",
    "    edges = g.adjacency_matrix().to(device)\n",
    "    Idmp = torch.ones([N]).to(device)*(1.0-DAMP)/N\n",
    "    gm = edges.to_dense().to(device)\n",
    "    gm = torch.mm(gm,torch.diag(degrees))\n",
    "    for k in range(K):\n",
    "        q = torch.mv(gm, pv)\n",
    "        pv  = Idmp + DAMP * q\n",
    "    return pv/pv.norm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = makeGraph(g1)\n",
    "t0 =time.time() \n",
    "pv = compute_pagerank(g, 'cpu')\n",
    "tser = time.time()-t0\n",
    "print('elapsed =', tser)\n",
    "\n",
    "g = makeGraph(g1)\n",
    "t0 =time.time() \n",
    "pvcu= compute_pagerank(g, 'cuda')\n",
    "tsercu = time.time()-t0\n",
    "print('elapsed =', tsercu)\n",
    "print('tser/tsercu=', tser/tsercu)\n",
    "print(pv)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "using aws and the neteworkx dgl library from https://docs.dgl.ai/ NYU Shanghai by Prof. Zheng Zhang and Quan Gan\n",
    "elapsed = 8.776297569274902\n",
    "elapsed = 2.1371102333068848\n",
    "tser/tsercu= 4.106619037472291\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = makeGraph(g1)\n",
    "t0 =time.time() \n",
    "pv1 = compute_pagerank1(g, K, 'cpu')\n",
    "tv1cpu = time.time()-t0\n",
    "print('elapsed =', tv1cpu)\n",
    "print((pv - pv1.T.to('cpu')).norm())\n",
    "\n",
    "g = makeGraph(g1)\n",
    "t0 =time.time() \n",
    "pv1cu = compute_pagerank1(g, K, 'cuda')\n",
    "tv1cu =  time.time()-t0\n",
    "print('elapsed =', tv1cu)\n",
    "print('cpu/cu=', tv1cpu/tv1cu, ' tser/cu=',tser/tv1cu )\n",
    "print((pv - pv1cu.T.to('cpu')).norm())\n",
    "print(pv1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pagerank1 uses the sparse graph library.\n",
    "elapsed = 26.387232303619385\n",
    "tensor(3.2224e-07)\n",
    "elapsed = 8.013639688491821\n",
    "cpu/cu= 3.292789959288212  tser/cu= 1.095169973997996891\n",
    "tensor(8.6448e-07)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = makeGraph(g1)\n",
    "t0 =time.time() \n",
    "pv2 = compute_pagerank2(g, K, 'cpu')\n",
    "tv2cpu = time.time()-t0\n",
    "print('elapsed =', tv2cpu)\n",
    "print((pv/pv.norm() - pv2.T.to('cpu')).norm())\n",
    "\n",
    "g = makeGraph(g1)\n",
    "t0 =time.time() \n",
    "pv2cu = compute_pagerank2(g, K, 'cuda')\n",
    "tv2cu =  time.time()-t0\n",
    "print('elapsed =', tv2cu)\n",
    "print('cpu/cu=', tv2cpu/tv2cu, ' tser/cu2=',tser/tv2cu, ' tv1cu/cu2=', tv1cu/tv2cu)\n",
    "print((pv/pv.norm() - pv2cu.T.to('cpu')).norm())\n",
    "print(pv2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "version 2 uses sparce-to-dense and full dense algebra.\n",
    "elapsed = 6.990988731384277\n",
    "tensor(1.5367e-06)\n",
    "elapsed = 0.07214999198913574\n",
    "cpu/cu= 96.89521147052895  tser/cu2= 121.63961945548694  tv1cu/cu2= 111.06916948374028\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = makeGraph(g1)\n",
    "t0 =time.time() \n",
    "pv3 = compute_pagerank3(g, K, 'cpu')\n",
    "print('elapsed =', time.time()-t0)\n",
    "print((pv - pv3.T.to('cpu')).norm())\n",
    "print((pv2 - pv3.to('cpu')).norm())\n",
    "print(pv3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "elapsed = 20.135096073150635\n",
    "elapsed = 0.07111024856567383\n",
    "cpu/cu= 283.1532230485016  tser/cu2= 121.63961945548694  tv2cu/tvcu3= 1.0146215692454184"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print((pv/pv.norm())[0:20])\n",
    "print(pv2.T[0:20])\n",
    "print(pv2cu.T[0:20])\n",
    "print(pv4.T[0:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
