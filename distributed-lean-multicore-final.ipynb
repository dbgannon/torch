{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.multiprocessing import Process\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    x = torch.randn(4, 4)\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_process(rank, size,fn, backend='gloo'):\n",
    "    \"\"\" Initialize the distributed environment. \"\"\"\n",
    "    os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "    os.environ['MASTER_PORT'] = '29500'\n",
    "    dist.init_process_group(backend, rank=rank, world_size=size)\n",
    "    fn(rank, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.il  = nn.Linear(1,80)\n",
    "        self.mi  = nn.Linear(80,80)\n",
    "        self.mi2 = nn.Linear(80,40)\n",
    "        self.ol  = nn.Linear(40,1)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self,x):\n",
    "        hidden1 = self.il(x)\n",
    "        hidden2 = self.mi(self.relu(hidden1))\n",
    "        hidden3 = self.mi2(self.relu(hidden2))\n",
    "        out =     self.ol(self.relu(hidden3))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 80000\n",
    "M = 4\n",
    "BS = 1000\n",
    "epocs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_fit(m):\n",
    "    x_in2 = [0.5*i for i in range(40)]\n",
    "    def yfun(i):\n",
    "        return np.sqrt(i)*np.sin(4*3.14*i/20.0)\n",
    "    y_vals2 = [yfun(i) for i in x_in2]\n",
    "    inputs2 = torch.tensor([x_in2]).T\n",
    "    targets2 = torch.tensor([y_vals2]).T\n",
    "    y = m(inputs2)\n",
    "    yy = y.detach().numpy()\n",
    "    plt.plot(x_in2, yy, 'o-')\n",
    "    plt.plot(x_in2, y_vals2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_initial_weights(model, rank, world_size):\n",
    "    for param in model.parameters():\n",
    "        if rank == 0:\n",
    "            # Rank 0 is sending it's own weight\n",
    "            # to all it's siblings (1 to world_size)\n",
    "            for sibling in range(1, world_size):\n",
    "                dist.send(param.data, dst=sibling)\n",
    "        else:\n",
    "            # Siblings must recieve the parameters\n",
    "            dist.recv(param.data, src=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_gradients(model, rank, world_size):\n",
    "    for param in model.parameters():\n",
    "        dist.all_reduce(param.grad.data, op=dist.ReduceOp.SUM)\n",
    "        param.grad.data = param.grad.data/world_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_model(model, rank, world_size):\n",
    "    print(\"model for rank \", rank)\n",
    "    for param in model.parameters():\n",
    "        if rank == 0:\n",
    "            print(param)\n",
    "            print(param.data)           \n",
    "        dist.all_reduce(param.data, op=dist.ReduceOp.SUM)\n",
    "        param.data = param.data/world_size\n",
    "        if rank == 0:\n",
    "            print(' now after reduce')\n",
    "            print(param)\n",
    "            print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_model(model, rank, world_size):\n",
    "    for param in model.parameters():\n",
    "        dist.all_reduce(param.data, op=dist.ReduceOp.SUM)\n",
    "        param.data = param.data/world_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_in = [(20.0/N)*random.randint(0,N) for i in range(N)]\n",
    "def yfun(x):\n",
    "    return np.sqrt(x)*np.sin(3.14*x/5.0)\n",
    "y_vals = [yfun(x) for x in x_in]\n",
    "\n",
    "def mk_minibatch(i, size):  \n",
    "    s = int(size)\n",
    "    my_in = x_in[s*i: s*(i+1)]\n",
    "    my_vals = y_vals[s*i: s*(i+1)]\n",
    "    return (my_in, my_vals)\n",
    "\n",
    "batches = [mk_minibatch(i, BS) for i in range(int(N/BS))]\n",
    "k = len(batches)\n",
    "print(k, M)\n",
    "batch = []\n",
    "s = 0\n",
    "for i in range(M):\n",
    "    bat = []\n",
    "    for j in range(int(k/M)):\n",
    "        bat.append(batches[s+j])\n",
    "        #print(i, M, k, j, s, s+j)\n",
    "    batch.append(bat)\n",
    "    s+= int(k/M)\n",
    "    \n",
    "def batchtodev(rank, device):\n",
    "    btch =batch[rank]\n",
    "    devb = []\n",
    "    for x in btch:\n",
    "        xin = torch.tensor([x[0]], device=device).T\n",
    "        yin = torch.tensor([x[1]], device=device).T\n",
    "        devb.append((xin, yin))\n",
    "    return devb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(rank, size):\n",
    "    device=\"cpu\"\n",
    "    model = Net().to(device)\n",
    "    print('my rank is ', rank, ' out of ', size)\n",
    "    sync_initial_weights(model, rank, size)\n",
    "    \n",
    "    btch = batchtodev(rank, device)\n",
    "    print('batch has ', len(btch), ' elements')\n",
    "    print(\"len of btch[0][0]=\", len(btch[0][0]))\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.005)\n",
    "    ta = time.time()\n",
    "    for epoc in range(1,epocs):\n",
    "        for b in btch:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(b[0])\n",
    "            loss = loss_fn(outputs, b[1])\n",
    "            loss.backward()\n",
    "            if epoc % 10  == 0:\n",
    "                sync_gradients(model, rank, size)\n",
    "            optimizer.step()\n",
    "        if epoc % 200 == 0:\n",
    "            average_model(model,rank, size)\n",
    "            #sync_gradients(model, rank, size)\n",
    "\n",
    "        if epoc % 1000 == 0:\n",
    "            tb = time.time()\n",
    "            elapse = tb-ta\n",
    "            ta = time.time()\n",
    "            #sync_gradients(model, rank, size)\n",
    "            print('epoc %d loss %f elapse %f'%(epoc, float(loss), elapse))\n",
    "\n",
    "    if rank == 0:\n",
    "        torch.save(model.state_dict(), \"/tmp/model\")\n",
    "    #show_model(model,rank, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my rank is  1  out of  4\n",
      "my rank is  0  out of  4\n",
      "my rank is  3  out of  4\n",
      "my rank is  2  out of  4\n",
      "batch has  20  elements\n",
      "batch has  20  elements\n",
      "len of btch[0][0]= 1000\n",
      "batch has  20  elements\n",
      "len of btch[0][0]= 1000\n",
      "len of btch[0][0]= 1000\n",
      "batch has  20  elements\n",
      "len of btch[0][0]= 1000\n",
      "epoc 1000 loss 1.580778 elapse 83.785775\n",
      "epoc 1000 loss 1.112996 elapse 83.795451\n",
      "epoc 1000 loss 0.772435 elapse 83.763190\n",
      "epoc 1000 loss 1.183104 elapse 83.784999\n",
      "epoc 2000 loss 0.092150 elapse 83.466444\n",
      "epoc 2000 loss 0.816509 elapse 83.466567\n",
      "epoc 2000 loss 0.093433 elapse 83.466534\n",
      "epoc 2000 loss 0.068608 elapse 83.466437\n",
      "epoc 3000 loss 0.130762 elapse 86.214714\n",
      "epoc 3000 loss 0.150380 elapse 86.217446\n",
      "epoc 3000 loss 0.142085 elapse 86.217384\n",
      "epoc 3000 loss 0.091100 elapse 86.216580\n",
      "epoc 4000 loss 0.298993 elapse 93.983464\n",
      "epoc 4000 loss 0.052613 elapse 93.982752\n",
      "epoc 4000 loss 0.025358 elapse 93.983884\n",
      "epoc 4000 loss 0.024898 elapse 93.983337\n",
      "epoc 5000 loss 0.217339 elapse 99.549428\n",
      "epoc 5000 loss 0.030208 elapse 99.549917\n",
      "epoc 5000 loss 0.014370 elapse 99.550579\n",
      "epoc 5000 loss 0.011563 elapse 99.548848\n",
      "epoc 6000 loss 0.004187 elapse 101.172828\n",
      "epoc 6000 loss 0.134807 elapse 101.174675\n",
      "epoc 6000 loss 0.028632 elapse 101.172910\n",
      "epoc 6000 loss 0.009554 elapse 101.173286\n",
      "epoc 7000 loss 0.026745 elapse 100.775092\n",
      "epoc 7000 loss 0.037078 elapse 100.776950\n",
      "epoc 7000 loss 0.016183 elapse 100.777125\n",
      "epoc 7000 loss 0.045003 elapse 100.776078\n",
      "epoc 8000 loss 0.018029 elapse 101.889273\n",
      "epoc 8000 loss 0.011127 elapse 101.890726\n",
      "epoc 8000 loss 0.038384 elapse 101.889272\n",
      "epoc 8000 loss 0.035350 elapse 101.891437\n",
      "epoc 9000 loss 0.016144 elapse 107.242983\n",
      "epoc 9000 loss 0.025735 elapse 107.243423\n",
      "epoc 9000 loss 0.013611 elapse 107.242763\n",
      "epoc 9000 loss 0.026906 elapse 107.244967\n",
      "elapse =  962.8057432174683\n"
     ]
    }
   ],
   "source": [
    "processes = []\n",
    "t0 = time.time()\n",
    "for rank in range(M):\n",
    "    p = Process(target=init_process, args=(rank, M, run))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "    \n",
    "for p in processes:\n",
    "    p.join()\n",
    "print(\"elapse = \", time.time()-t0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for N = 80000, BS = 1000, epocs = 10000, \n",
    "M = 1  elapse = 2612\n",
    "M = 2  elapse = 654\n",
    "M = 4  elapse = 771\n",
    "for N = 8000, BS = 100, epocs = 10000, \n",
    "M = 1  elapse = 869\n",
    "M = 2  elapse = 182 189\n",
    "M = 3  elapse = 208\n",
    "M = 4  elapse = 206\n",
    "for N = 8000, BS = 1000, epocs = 10000, \n",
    "M = 1  elapse = 278\n",
    "M = 2  elapse = 56\n",
    "M = 3  elapse = 44\n",
    "M = 4  elapse = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = Net()\n",
    "m0.load_state_dict(torch.load(\"/tmp/model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_fit(m0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in = [0.025*random.randint(0,800) for i in range(800)]\n",
    "def yfun(i):\n",
    "    return np.sqrt(i)*np.sin(4*3.14*i/20.0)\n",
    "y_vals = [yfun(i) for i in x_in]\n",
    "inputs = torch.tensor([x_in]).T\n",
    "targets = torch.tensor([y_vals]).T\n",
    "loss_fn = nn.MSELoss()\n",
    "    \n",
    "mouts = m0(inputs)\n",
    "err = loss_fn(mouts, targets)\n",
    "print(\"err =\", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "134/39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}